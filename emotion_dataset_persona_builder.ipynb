{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python3\n", "# -*- coding: utf-8 -*-\n", "\"\"\"\n", "Created on Fri Jan  2 21:17:52 2026"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@author: Daku\n", "\"\"\"\n", "import re\n", "import numpy as np\n", "import pandas as pd\n", "from tqdm import tqdm"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from scipy.sparse import hstack, csr_matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer\n", "from sklearn.linear_model import SGDClassifier, LogisticRegression\n", "from sklearn.multiclass import OneVsRestClassifier\n", "from sklearn.decomposition import TruncatedSVD\n", "from sklearn.cluster import MiniBatchKMeans\n", "from sklearn.metrics.pairwise import cosine_similarity\n", "from sklearn.preprocessing import normalize"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------Loading and cleaning the original Kaggle dataset----------------------# "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["DATA_PATH = \"/Users/Daku/Desktop/OpenAI_Residency/Datasets/emotion_sentimen_dataset.csv\"\n", "df = pd.read_csv(DATA_PATH)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = df.drop(columns=[\"Unnamed: 0\"], errors=\"ignore\")\n", "df = df.dropna(subset=[\"text\", \"Emotion\"]).copy()\n", "df[\"text\"] = df[\"text\"].astype(str).str.strip()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(df.shape)\n", "print(df[\"Emotion\"].value_counts().head(10))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---------------Loading the csv containing digitized flash cards from \"Box of Emotions\"-----------# <br>\n", "------------------------The cards will be treated as theory anchors------------------------------# "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["CARDS_PATH = \"/Users/Daku/Desktop/OpenAI_Residency/Datasets/cards.csv\"\n", "cards = pd.read_csv(CARDS_PATH).dropna(subset=[\"card_name\", \"definition\"]).copy()\n", "cards[\"card_name\"] = cards[\"card_name\"].astype(str).str.strip()\n", "cards[\"system\"] = cards[\"system\"].astype(str).str.strip()\n", "cards[\"definition\"] = cards[\"definition\"].astype(str).str.strip()\n", "print(cards.shape)\n", "print(cards[\"system\"].value_counts())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["------------------Vectorize the card definitions into a card embeddings space--------------------#"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["card_vec = TfidfVectorizer(\n", "    stop_words=\"english\",\n", "    ngram_range=(1,2),\n", "    min_df=1\n", ")\n", "C = card_vec.fit_transform(cards[\"definition\"])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["------------Create psychological and behavioral cue features from text-----------------------# <br>\n", "Simple lexicons (TODO: expand this)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["NEGATIONS = set([\"not\",\"no\",\"never\",\"none\",\"nothing\",\"n't\"])\n", "MODALS = set([\"should\",\"must\",\"need\",\"have to\",\"can't\",\"cannot\",\"could\",\"might\",\"may\"])\n", "TIME_PAST = re.compile(r\"\\b(was|were|had|did|ago|yesterday|before)\\b\", re.I)\n", "TIME_FUTURE = re.compile(r\"\\b(will|gonna|going to|tomorrow|next|soon|might)\\b\", re.I)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MORAL = re.compile(r\"\\b(deserve|fault|blame|wrong|should|ought|fair|unfair|shame|guilt)\\b\", re.I)\n", "THREAT = re.compile(r\"\\b(threat|danger|scared|fear|panic|terrified|unsafe)\\b\", re.I)\n", "LOSS = re.compile(r\"\\b(miss|lost|gone|grief|sad|lonely|heartbroken)\\b\", re.I)\n", "COMPARE = re.compile(r\"\\b(better|worse|than|others|they have|why them)\\b\", re.I)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def cue_features(text: str) -> np.ndarray:\n", "    t = text.lower()\n", "    tokens = re.findall(r\"[a-z']+\", t)\n", "    n = max(len(tokens), 1)\n\n", "    # pronoun focus\n", "    i_cnt = sum(tok in (\"i\",\"me\",\"my\",\"mine\") for tok in tokens)\n", "    you_cnt = sum(tok in (\"you\",\"your\",\"yours\") for tok in tokens)\n", "    they_cnt = sum(tok in (\"they\",\"them\",\"their\",\"theirs\") for tok in tokens)\n\n", "    # simple counts\n", "    neg = sum(tok in NEGATIONS for tok in tokens)\n", "    exclam = text.count(\"!\")\n", "    ques = text.count(\"?\")\n", "    caps = sum(1 for ch in text if ch.isalpha() and ch.isupper())\n", "    alpha = sum(1 for ch in text if ch.isalpha())\n", "    caps_ratio = caps / max(alpha, 1)\n\n", "    # pattern hits\n", "    past = 1 if TIME_PAST.search(text) else 0\n", "    future = 1 if TIME_FUTURE.search(text) else 0\n", "    moral = 1 if MORAL.search(text) else 0\n", "    threat = 1 if THREAT.search(text) else 0\n", "    loss = 1 if LOSS.search(text) else 0\n", "    compare = 1 if COMPARE.search(text) else 0\n", "    return np.array([\n", "        len(tokens),                 # length\n", "        i_cnt / n, you_cnt / n, they_cnt / n,\n", "        neg / n,\n", "        exclam, ques,\n", "        caps_ratio,\n", "        past, future,\n", "        moral, threat, loss, compare\n", "    ], dtype=float)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def build_cue_matrix(texts: pd.Series, batch_size=50000) -> csr_matrix:\n", "    feats = []\n", "    for start in tqdm(range(0, len(texts), batch_size)):\n", "        chunk = texts.iloc[start:start+batch_size]\n", "        arr = np.vstack([cue_features(x) for x in chunk])\n", "        feats.append(csr_matrix(arr))\n", "    return csr_matrix(np.vstack([f.toarray() for f in feats]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For a first run, sample (scale up after debugging)<br>\n", "sample = df.sample(n=min(200000, len(df)), random_state=42).reset_index(drop=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_cues = build_cue_matrix(df[\"text\"])\n", "print(X_cues.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-----Learning expression of emotions (Linguistic Expression Model)------------# "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["text_vec = HashingVectorizer(\n", "    n_features=2**20,\n", "    alternate_sign=False,\n", "    ngram_range=(1,2),\n", "    token_pattern=r\"(?u)\\b[\\w']+\\b\"\n", ")\n", "X_text = text_vec.transform(df[\"text\"])\n", "y = df[\"Emotion\"].values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = hstack([X_text, X_cues]).tocsr()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(\n", "    X, y, test_size=0.2, random_state=42, stratify=y\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["clf = SGDClassifier(loss=\"log_loss\", alpha=1e-6, max_iter=200, n_jobs=-1)\n", "clf.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Baseline emotion model trained.\")\n", "print(\"Test accuracy (rough):\", clf.score(X_test, y_test))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["----------------Interrogate dataset against card theory---------------------#<br>\n", "a) Build card similarity score on each text <br>\n", "Card-space vectorizer: fit on (cards + data sample) so vocabulary covers both"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["card_space_vec = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), min_df=5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["combined = pd.concat([cards[\"definition\"], df[\"text\"]], ignore_index=True)\n", "card_space_vec.fit(combined)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["C = card_space_vec.transform(cards[\"definition\"])  \n", "T = card_space_vec.transform(df[\"text\"])       "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Similarity: each text gets similarity to each card definition"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["S = cosine_similarity(T, C) # this cannot be done for the full dataset as this \n", "# breaks and needs chunking to avoid S vector to have ~63 million floats\n", "print(\"Cosing similaraity completed!\")\n", "# --------Extract top-k card lenses per text (the theory projection)-----#"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["card_names = cards[\"card_name\"].tolist()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TOPK = 3\n", "topk_idx = np.argsort(-S, axis=1)[:, :TOPK]\n", "topk_cards = [[card_names[j] for j in row] for row in topk_idx]\n", "topk_scores = np.take_along_axis(S, topk_idx, axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[\"theory_cards_top3\"] = [\";\".join(x) for x in topk_cards]\n", "df[\"theory_top1\"] = [x[0] for x in topk_cards]\n", "df[\"theory_top1_score\"] = topk_scores[:,0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[[\"Emotion\", \"theory_top1\", \"theory_top1_score\"]].head(10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ecompose expressions into psychological and behavioral cues (structured inference)------------# "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cue_cols = [\n", "    \"len_tokens\",\"i_ratio\",\"you_ratio\",\"they_ratio\",\"neg_ratio\",\n", "    \"exclam\",\"ques\",\"caps_ratio\",\"past\",\"future\",\"moral\",\"threat\",\"loss\",\"compare\"\n", "]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cue_df = pd.DataFrame(X_cues.toarray(), columns=cue_cols)\n", "tmp = pd.concat([df[[\"Emotion\",\"theory_top1\"]], cue_df], axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["summary = tmp.groupby([\"Emotion\",\"theory_top1\"])[cue_cols].mean().sort_values(\"threat\", ascending=False)\n", "summary.head(20)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------Build personas from mechanisms-------------------# "]}, {"cell_type": "markdown", "metadata": {}, "source": ["---- a) Create a \u201cpersona feature matrix-----------# <br>\n", "Reduce the 79-d theory similarity into smaller dimensions for clustering stability"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["svd = TruncatedSVD(n_components=25, random_state=42)\n", "S_reduced = svd.fit_transform(S)  # [N, 25]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_persona = hstack([X_cues, csr_matrix(S_reduced)]).tocsr()\n", "print(X_persona.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---- b) Cluster into Personas -------------------# "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["k = 8  # start with 6\u201310; tune later via stability + interpretability\n", "km = MiniBatchKMeans(n_clusters=k, random_state=42, batch_size=4096, n_init=\"auto\")\n", "persona_id = km.fit_predict(X_persona)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[\"persona_id\"] = persona_id\n", "df[\"persona_id\"].value_counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-------Make Personas Interpretable---------------# "]}, {"cell_type": "markdown", "metadata": {}, "source": ["-------naming personas using top theory cards, cue profiles and texts----#"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def top_items(series, n=5):\n", "    return series.value_counts().head(n).to_dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["persona_reports = []\n", "for pid in sorted(df[\"persona_id\"].unique()):\n", "    sub = df[df[\"persona_id\"] == pid]\n", "    \n", "    # Top theory lenses\n", "    top_theory = top_items(sub[\"theory_top1\"], n=7)\n", "    \n", "    # Cue means\n", "    cue_means = cue_df.loc[sub.index].mean().to_dict()\n", "    \n", "    # Representative examples (highest top1 score)\n", "    ex = sub.sort_values(\"theory_top1_score\", ascending=False).head(3)[\"text\"].tolist()\n", "    \n", "    persona_reports.append({\n", "        \"persona_id\": pid,\n", "        \"size\": len(sub),\n", "        \"top_theory_cards\": top_theory,\n", "        \"cue_means\": cue_means,\n", "        \"examples\": ex\n", "    })"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["persona_reports[0][\"top_theory_cards\"], persona_reports[0][\"examples\"][:1]"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}